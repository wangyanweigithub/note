 

流水车间调度程序

克里斯蒂安·穆伊斯（Christian Muise）博士

基督教Muise博士是研究员与MERS组在MIT的CSAIL。他对各种主题感兴趣，包括AI，数据驱动项目，映射，
图论和数据可视化，以及凯尔特音乐，雕刻，足球和咖啡。

流水车间调度程序

流水作业调度是运筹学中最具挑战性和研究充分的问题之一。像许多具有挑战性的优化问题一样，对于实际
规模的问题，不可能找到最佳解决方案。在本章中，我们考虑使用称为本地搜索的技术实现流水车间调度求
解器。本地搜索使我们能够在无法找到最佳解决方案时找到“相当不错”的解决方案。求解器将尝试在给定的
时间内找到问题的新解决方案，最后返回找到的最佳解决方案。

本地搜索的思想是通过考虑可能更好的类似解决方案来启发式地改进现有解决方案。求解器使用多种策略来
（1）尝试寻找相似的解决方案，并且（2）选择有希望进一步探索的解决方案。该实现是用Python编写的，
没有任何外部要求。通过利用Python的一些鲜为人知的功能，求解器会在求解过程中根据效果良好的策略动
态更改其搜索策略。

首先，我们提供一些有关流水车间调度问题和本地搜索技术的背景材料。然后，我们详细研究通用求解器代
码以及所使用的各种试探法和邻域选择策略。接下来，我们考虑求解器用来将所有内容绑定在一起的动态策
略选择。最后，我们对项目进行了总结，并从实施过程中学到了一些经验教训。

背景

流水车间调度

流水车间调度问题是一个优化问题，其中我们必须确定作业中各种任务的处理时间，以便调度任务以最大程
度地减少完成作业所需的总时间。例如，一家汽车制造商拥有一条装配线，其中汽车的每个零件都在不同的
机器上依次完成。不同的订单可能有自定义要求，例如，使车身涂漆的任务因一辆汽车而异。在我们的示例
中，每辆汽车都是新工作，每辆汽车的零件都称为任务。每个作业将具有相同的任务序列来完成。

流水车间调度的目的是最大程度地减少处理从每个作业到完成所有任务的总时间。（通常，此总时间称为完
成时间。）此问题有很多应用程序，但与优化生产设备最相关。

每个流水车间问题都包括 ññ 机器和 米米工作。在我们的汽车示例中，ññ 在汽车上工作的车站和 米米总
共要制造的汽车。每个工作都是完全由ññ 任务，我们可以假设 一世一世工作的第一个任务必须使用机器 
一世一世并需要预定的处理时间： p （j ，i ）p（Ĵ，一世）是处理时间 一世一世工作任务 ĴĴ。此外，
任何给定作业的任务顺序都应遵循可用机器的顺序。对于给定的工作，任务一世一世必须在任务开始之前完
成 我+ 1一世+1个。在我们的汽车示例中，我们不想在组装框架之前就开始为汽车涂漆。最后的限制是不能
在计算机上同时处理两个任务。

因为作业中任务的顺序是预先确定的，所以流水车间调度问题的解决方案可以表示为作业的排列。对于每台
机器，在一台机器上处理的作业的顺序将是相同的，并且给定排列后，机器的一项任务一世一世在工作中 Ĵ
Ĵ 预定为以下两种可能性中的最新一种：

 1. 完成机器的任务 一世一世在工作中 j − 1Ĵ-1个（即同一台计算机上的最新任务），或

 2. 完成机器的任务 i − 1一世-1个在工作中 ĴĴ （即，同一工作上的最新任务）

因为我们选择这两个值中的最大值，所以任一台机器的空闲时间 一世一世或工作 ĴĴ将被创建。我们最终希
望最小化此空闲时间，因为它将使总有效期变大。

由于问题的简单形式，作业的任何排列都是有效的解决方案，而最佳解决方案将对应于某些排列。因此，我
们通过更改作业的排列并测量相应的有效期来寻求改进的解决方案。在下文中，我们将作业的排列称为候选
。

让我们考虑一个简单的示例，其中包含两个作业和两个计算机。第一份工作有任务一个一个和 乙乙，分别
需要1分钟和2分钟才能完成。第二份工作有任务CC 和 dd，分别需要2分钟和1分钟才能完成。回想起那个
一个一个必须在之前 乙乙和 CC 必须在之前 dd。因为有两个工作，所以我们只考虑两个排列。如果在工作
1之前订购工作2，则制造跨度为5（图9.1）；另一方面，如果我们在作业2之前订购作业1，则制造跨度仅为
4（图9.2）。

图9.1-Flow Shop示例1

图9.1-Flow Shop示例1

图9.2-Flow Shop示例2

图9.2-Flow Shop示例2

请注意，没有多余的空间可以提前执行任何任务。良好排列的指导原则是最大程度地缩短任何机器无需处理
的时间。

本地搜寻

当最佳解决方案太难计算时，局部搜索是解决优化问题的策略。直观地讲，它从一个看起来不错的解决方案
过渡到另一个看起来更好的解决方案。我们没有定义所有可能的解决方案作为接下来要关注的候选方案，而
是定义了所谓的邻域：被认为与当前解决方案相似的一组解决方案。因为作业的任何排列都是有效的解决方
案，所以我们可以将任何将作业混洗的机制视为本地搜索过程（实际上，这是我们在下面的工作）。

要正式使用本地搜索，我们必须回答以下几个问题：

 1. 我们应该从什么解决方案开始？
 2. 给定一个解决方案，我们应该考虑哪些邻近解决方案？
 3. 给定一组候选邻居，我们应该考虑移至下一个？

以下三个部分依次解决了这些问题。

通用求解器

在本节中，我们提供了流水车间调度程序的一般框架。首先，我们具有必要的Python导入和求解器的设置：

import sys, os, time, random

from functools import partial
from collections import namedtuple
from itertools import product

import neighbourhood as neigh
import heuristics as heur

##############
## Settings ##
##############
TIME_LIMIT = 300.0 # Time (in seconds) to run the solver
TIME_INCREMENT = 13.0 # Time (in seconds) in between heuristic measurements
DEBUG_SWITCH = False # Displays intermediate heuristic info when True
MAX_LNS_NEIGHBOURHOODS = 1000 # Maximum number of neighbours to explore in LNS

有两个设置应进一步说明。该TIME_INCREMENT设置将用作动态策略选择的一部分，而该
MAX_LNS_NEIGHBOURHOODS设置将用作邻域选择策略的一部分。两者都在下面更详细地描述。

这些设置可以作为命令行参数显示给用户，但是在此阶段，我们改为将输入数据作为参数提供给程序。输入
问题（来自Taillard基准集的问题）被假定为流水车间调度的标准格式。以下代码用作__main__求解器文件
的方法，并根据输入到程序的参数数量调用适当的函数：

if __name__ == '__main__':

    if len(sys.argv) == 2:
        data = parse_problem(sys.argv[1], 0)
    elif len(sys.argv) == 3:
        data = parse_problem(sys.argv[1], int(sys.argv[2]))
    else:
        print "\nUsage: python flow.py <Taillard problem file> [<instance number>]\n"
        sys.exit(0)

    (perm, ms) = solve(data)
    print_solution(data, perm)

我们将在短期内描述Taillard问题文件的解析。（这些文件可在线获得。）

该solve方法期望data变量是包含每个作业的活动持续时间的整数列表。该solve方法开始于初始化一组全局
策略（将在下面进行描述）。关键是我们使用strat_*变量来维护每个策略的统计数据。这有助于在求解过
程中动态选择策略。

def solve(data):
    """Solves an instance of the flow shop scheduling problem"""

    # We initialize the strategies here to avoid cyclic import issues
    initialize_strategies()
    global STRATEGIES

    # Record the following for each strategy:
    #  improvements: The amount a solution was improved by this strategy
    #  time_spent: The amount of time spent on the strategy
    #  weights: The weights that correspond to how good a strategy is
    #  usage: The number of times we use a strategy
    strat_improvements = {strategy: 0 for strategy in STRATEGIES}
    strat_time_spent = {strategy: 0 for strategy in STRATEGIES}
    strat_weights = {strategy: 1 for strategy in STRATEGIES}
    strat_usage = {strategy: 0 for strategy in STRATEGIES}

流水车间调度问题的一个吸引人的特征是，每个排列都是有效的解决方案，并且至少有一个将具有最佳的制
造期（尽管许多将具有可怕的制造期）。值得庆幸的是，当从一个排列转换到另一个排列时，这可以让我们
放弃检查是否处于可行解的空间之内，所有一切都是可行的！

但是，要在置换空间中开始局部搜索，我们必须具有初始置换。为简单起见，我们通过随机排列作业列表来
播种本地搜索：

    # Start with a random permutation of the jobs
    perm = range(len(data))
    random.shuffle(perm)

接下来，我们初始化变量，以使我们能够跟踪迄今为止找到的最佳排列以及用于提供输出的时序信息。

    # Keep track of the best solution
    best_make = makespan(data, perm)
    best_perm = perm
    res = best_make

    # Maintain statistics and timing for the iterations
    iteration = 0
    time_limit = time.time() + TIME_LIMIT
    time_last_switch = time.time()

    time_delta = TIME_LIMIT / 10
    checkpoint = time.time() + time_delta
    percent_complete = 10

    print "\nSolving..."

由于这是本地搜索解决方案，因此只要没有达到时间限制，我们就可以继续尝试并改进解决方案。我们提供
指示求解器进度的输出，并跟踪我们计算出的迭代次数：

    while time.time() < time_limit:

        if time.time() > checkpoint:
            print " %d %%" % percent_complete
            percent_complete += 10
            checkpoint += time_delta

        iteration += 1

下面我们描述如何选择策略，但是到目前为止，知道策略提供了一个neighbourhood功能和一个heuristic功
能就足够了。前者为我们提供了一组下一个要考虑的候选人，而后者则从集合中选择了最佳候选人。从这些
函数中，我们得到一个新的置换（perm）和一个新的制造期结果（res）：

        # Heuristically choose the best strategy
        strategy = pick_strategy(STRATEGIES, strat_weights)

        old_val = res
        old_time = time.time()

        # Use the current strategy's heuristic to pick the next permutation from
        # the set of candidates generated by the strategy's neighbourhood
        candidates = strategy.neighbourhood(data, perm)
        perm = strategy.heuristic(data, candidates)
        res = makespan(data, perm)

计算工期的代码非常简单：我们可以通过评估最终作业的完成时间来从排列中进行计算。我们将在下面看到
compile_solution工作原理，但是到目前为止，只需知道已返回2D数组，并且处的元素[-1][-1]对应于计划
中最终作业的开始时间即可：

def makespan(data, perm):
    """Computes the makespan of the provided solution"""
    return compile_solution(data, perm)[-1][-1] + data[perm[-1]][-1]

为了帮助选择策略，我们对以下方面进行统计：（1）该策略改善了解决方案的数量；（2）该策略花费了多
少时间计算信息；（3）使用该策略的次数。如果偶然发现更好的解决方案，我们还将更新变量以获得最佳
排列：

        # Record the statistics on how the strategy did
        strat_improvements[strategy] += res - old_val
        strat_time_spent[strategy] += time.time() - old_time
        strat_usage[strategy] += 1

        if res < best_make:
            best_make = res
            best_perm = perm[:]

定期更新用于策略的统计信息。为了便于阅读，我们删除了相关代码段，并在下面详细说明了代码。作为最
后一步，一旦while循环完成（即达到了时间限制），我们将输出有关求解过程的一些统计信息，并返回最
佳排列及其有效期：

    print " %d %%\n" % percent_complete
    print "\nWent through %d iterations." % iteration

    print "\n(usage) Strategy:"
    results = sorted([(strat_weights[STRATEGIES[i]], i)
                      for i in range(len(STRATEGIES))], reverse=True)
    for (w, i) in results:
        print "(%d) \t%s" % (strat_usage[STRATEGIES[i]], STRATEGIES[i].name)

    return (best_perm, best_make)

解析问题

作为解析过程的输入，我们提供了可以找到输入的文件名以及应使用的示例编号。（每个文件包含许多实例
。）

def parse_problem(filename, k=1):
    """Parse the kth instance of a Taillard problem file

    The Taillard problem files are a standard benchmark set for the problem
    of flow shop scheduling. 

    print "\nParsing..."

我们通过读取文件并标识分隔每个问题实例的行来开始解析：

    with open(filename, 'r') as f:
        # Identify the string that separates instances
        problem_line = ('/number of jobs, number of machines, initial seed, '
                        'upper bound and lower bound :/')

        # Strip spaces and newline characters from every line
        lines = map(str.strip, f.readlines())

为了使查找正确的实例更加容易，我们假设行将以'/'字符分隔。这样，我们就可以根据出现在每个实例顶
部的通用字符串来分割文件，并且在第一行的开头添加一个'/'字符可以使下面的字符串处理工作正常，无
论我们选择哪种实例。给定文件中找到的实例集合，我们还将检测提供的实例号何时超出范围。

        # We prep the first line for later
        lines[0] = '/' + lines[0]

        # We also know '/' does not appear in the files, so we can use it as
        #  a separator to find the right lines for the kth problem instance
        try:
            lines = '/'.join(lines).split(problem_line)[k].split('/')[2:]
        except IndexError:
            max_instances = len('/'.join(lines).split(problem_line)) - 1
            print "\nError: Instance must be within 1 and %d\n" % max_instances
            sys.exit(0)

我们直接解析数据，将每个任务的处理时间转换为整数并将其存储在列表中。最后，我们压缩数据以反转行
和列，以使格式尊重上述求解代码所期望的格式。（其中的每个项目data都应对应于特定的工作。）

        # Split every line based on spaces and convert each item to an int
        data = [map(int, line.split()) for line in lines]

    # We return the zipped data to rotate the rows and columns, making each
    #  item in data the durations of tasks for a particular job
    return zip(*data)

编译解决方案

流水车间调度问题的解决方案包括为每个作业中的每个任务确定准确的时间。因为我们隐含地表示工作的排
列，所以我们引入了compile_solution将排列转换为精确时间的函数。作为输入，该函数接收问题数据（为
我们提供每个任务的持续时间）和作业排列的数据。

该函数首先初始化用于存储每个任务的开始时间的数据结构，然后将第一个作业中的任务包括在排列中。

def compile_solution(data, perm):
    """Compiles a scheduling on the machines given a permutation of jobs"""

    num_machines = len(data[0])

    # Note that using [[]] * m would be incorrect, as it would simply
    #  copy the same list m times (as opposed to creating m distinct lists).
    machine_times = [[] for _ in range(num_machines)]

    # Assign the initial job to the machines
    machine_times[0].append(0)
    for mach in range(1,num_machines):
        # Start the next task in the job when the previous finishes
        machine_times[mach].append(machine_times[mach-1][0] +
                                   data[perm[0]][mach-1])

然后，我们添加剩余任务的所有任务。作业中的第一个任务将始终在上一个作业中的第一个任务完成后立即
开始。对于其余任务，我们会尽早安排作业：同一作业中上一个任务的完成时间和同一台计算机上上一个任
务的完成时间中的最大值。

    # Assign the remaining jobs
    for i in range(1, len(perm)):

        # The first machine never contains any idle time
        job = perm[i]
        machine_times[0].append(machine_times[0][-1] + data[perm[i-1]][0])

        # For the remaining machines, the start time is the max of when the
        #  previous task in the job completed, or when the current machine
        #  completes the task for the previous job.
        for mach in range(1, num_machines):
            machine_times[mach].append(max(
                machine_times[mach-1][i] + data[perm[i]][mach-1],
                machine_times[mach][i-1] + data[perm[i-1]][mach]))

    return machine_times

印刷解决方案

求解过程完成后，程序将以紧凑形式输出有关解决方案的信息。我们没有提供每项任务的每个任务的准确时
间安排，而是输出以下信息：

 1. 产生最佳生产期的工作排列
 2. 排列的计算的计算跨度
 3. 每台机器的开始时间，完成时间和空闲时间
 4. 每个作业的开始时间，完成时间和空闲时间

作业或机器的开始时间对应于作业或机器上第一个任务的开始。同样，作业或机器的完成时间对应于作业或
机器上最终任务的结束。空闲时间是特定作业或机器的任务之间的空闲时间。理想情况下，我们希望减少空
闲时间，因为这意味着总的处理时间也将减少。

已经讨论了用于编译解决方案的代码（即，计算每个任务的开始时间），并且输出排列和makepan很简单：

def print_solution(data, perm):
    """Prints statistics on the computed solution"""

    sol = compile_solution(data, perm)

    print "\nPermutation: %s\n" % str([i+1 for i in perm])

    print "Makespan: %d\n" % makespan(data, perm)

接下来，我们使用Python中的字符串格式化功能为每个机器和作业打印开始，结束和空闲时间表。请注意，
作业的空闲时间是从作业开始到完成为止的时间，减去该作业中每个任务的处理时间之和。我们以类似的方
式计算机器的空闲时间。

    row_format ="{:>15}" * 4
    print row_format.format('Machine', 'Start Time', 'Finish Time', 'Idle Time')
    for mach in range(len(data[0])):
        finish_time = sol[mach][-1] + data[perm[-1]][mach]
        idle_time = (finish_time - sol[mach][0]) - sum([job[mach] for job in data])
        print row_format.format(mach+1, sol[mach][0], finish_time, idle_time)

    results = []
    for i in range(len(data)):
        finish_time = sol[-1][i] + data[perm[i]][-1]
        idle_time = (finish_time - sol[0][i]) - sum([time for time in data[perm[i]]])
        results.append((perm[i]+1, sol[0][i], finish_time, idle_time))

    print "\n"
    print row_format.format('Job', 'Start Time', 'Finish Time', 'Idle Time')
    for r in sorted(results):
        print row_format.format(*r)

    print "\n\nNote: Idle time does not include initial or final wait time.\n"

邻里

本地搜索的思想是将本地解决方案从一个解决方案迁移到附近的其他解决方案。我们将给定解决方案的邻域
称为本地的其他解决方案。在本节中，我们将详细介绍四个潜在的社区，每个社区的复杂性都在不断提高。

第一邻域产生给定数量的随机排列。这个邻里甚至没有考虑我们开始时使用的解决方案，因此“邻里”一词扩
展了事实。但是，在搜索中包括一些随机性是一种好习惯，因为它可以促进对搜索空间的探索。

def neighbours_random(data, perm, num = 1):
    # Returns <num> random job permutations, including the current one
    candidates = [perm]
    for i in range(num):
        candidate = perm[:]
        random.shuffle(candidate)
        candidates.append(candidate)
    return candidates

对于下一个街区，我们考虑在置换中交换任意两个作业。通过使用包中的combinations函数itertools，我
们可以轻松地遍历每对索引，并创建对应于交换位于每个索引处的作业的新排列。从某种意义上说，这个邻
域产生的排列与我们开始时的排列非常相似。

def neighbours_swap(data, perm):
    # Returns the permutations corresponding to swapping every pair of jobs
    candidates = [perm]
    for (i,j) in combinations(range(len(perm)), 2):
        candidate = perm[:]
        candidate[i], candidate[j] = candidate[j], candidate[i]
        candidates.append(candidate)
    return candidates

我们考虑的下一个邻域使用特定于当前问题的信息。我们发现空闲时间最多的作业，并考虑以各种可能的方
式交换它们。我们采用的值size是我们考虑的作业数量：size最空闲的作业。该过程的第一步是计算排列中
每个作业的空闲时间：

def neighbours_idle(data, perm, size=4):
    # Returns the permutations of the <size> most idle jobs
    candidates = [perm]

    # Compute the idle time for each job
    sol = flow.compile_solution(data, perm)
    results = []

    for i in range(len(data)):
        finish_time = sol[-1][i] + data[perm[i]][-1]
        idle_time = (finish_time - sol[0][i]) - sum([t for t in data[perm[i]]])
        results.append((idle_time, i))

接下来，我们计算size空闲时间最多的作业列表。

    # Take the <size> most idle jobs
    subset = [job_ind for (idle, job_ind) in reversed(sorted(results))][:size]

最后，我们通过考虑已确定的最闲置作业的每个排列来构造邻域。为了找到排列，我们利用包中的
permutations函数itertools。

    # Enumerate the permutations of the idle jobs
    for ordering in permutations(subset):
        candidate = perm[:]
        for i in range(len(ordering)):
            candidate[subset[i]] = perm[ordering[i]]
        candidates.append(candidate)

    return candidates

我们考虑的最终邻域通常称为大邻域搜索（LNS）。直观上，LNS通过隔离考虑当前排列的较小子集来工作，
找到工作子集的最佳排列将为我们提供LNS社区的单个候选者。通过对特定大小的几个（或全部）子集重复
此过程，我们可以增加邻域中的候选者数量。我们限制通过MAX_LNS_NEIGHBOURHOODS参数考虑的数目，因为
邻居的数目可以快速增长。LNS计算的第一步是计算随机的作业集列表，我们将考虑使用软件包的
combinations功能进行交换itertools：

def neighbours_LNS(data, perm, size = 2):
    # Returns the Large Neighbourhood Search neighbours
    candidates = [perm]

    # Bound the number of neighbourhoods in case there are too many jobs
    neighbourhoods = list(combinations(range(len(perm)), size))
    random.shuffle(neighbourhoods)

接下来，我们遍历子集以找到每个作业的最佳排列。我们在上面已经看到了类似的代码，可以循环访问最空
闲的作业的所有排列。此处的主要区别在于，我们仅记录该子集的最佳排列，因为通过为所考虑的工作的每
个子集选择一个排列来构建更大的邻域。

    for subset in neighbourhoods[:flow.MAX_LNS_NEIGHBOURHOODS]:

        # Keep track of the best candidate for each neighbourhood
        best_make = flow.makespan(data, perm)
        best_perm = perm

        # Enumerate every permutation of the selected neighbourhood
        for ordering in permutations(subset):
            candidate = perm[:]
            for i in range(len(ordering)):
                candidate[subset[i]] = perm[ordering[i]]
            res = flow.makespan(data, candidate)
            if res < best_make:
                best_make = res
                best_perm = candidate

        # Record the best candidate as part of the larger neighbourhood
        candidates.append(best_perm)

    return candidates

如果我们将size参数设置为等于作业数，则将考虑每个排列并选择最佳排列。但是，实际上，我们需要将子
集的大小限制为3或4；任何较大的值都会导致该neighbours_LNS功能花费大量时间。

启发式

启发式方法从一组提供的候选中返回单个候选排列。试探法还被授予对问题数据的访问权限，以评估可能首
选的候选者。

我们考虑的第一个启发式方法是heur_random。这种试探法从列表中随机选择一个候选人，而不评估哪个人
可能更受欢迎：

def heur_random(data, candidates):
    # Returns a random candidate choice
    return random.choice(candidates)

下一个启发式heur_hillclimbing使用另一个极端。与其随机选择一个候选者，不如选择具有最佳跨度的候
选者。请注意，列表scores将包含以下形式的元组，(make,perm)其中make为置换的makepan值perm。对这样
的列表进行排序会将具有最佳生成时间的元组放在列表的开头；从这个元组中，我们返回排列。

def heur_hillclimbing(data, candidates):
    # Returns the best candidate in the list
    scores = [(flow.makespan(data, perm), perm) for perm in candidates]
    return sorted(scores)[0][1]

最终的启发式heur_random_hillclimbing结合了上面的随机启发式和爬山式启发式。执行本地搜索时，您可
能并不总是希望选择一个随机的候选者，甚至是最好的候选者。该heur_random_hillclimbing启发式收益率
的概率为0选择的最佳人选了“相当不错”的解决方案，那么第二个最好的概率为0.25，依此类推。while循环
实际上在每次迭代时都会掷硬币，以查看它是否应继续增加索引（限制列表的大小）。选择的最终索引对应
于启发式选择的候选者。

def heur_random_hillclimbing(data, candidates):
    # Returns a candidate with probability proportional to its rank in sorted quality
    scores = [(flow.makespan(data, perm), perm) for perm in candidates]
    i = 0
    while (random.random() < 0.5) and (i < len(scores) - 1):
        i += 1
    return sorted(scores)[i][1]

由于makepan是我们正在尝试优化的标准，因此爬坡将引导本地搜索过程转向具有更好的makepan的解决方案
。引入随机性使我们能够探索邻居，而不是在每一步都盲目追求最佳外观的解决方案。

动态策略选择

寻求良好排列的本地搜索的核心是使用特定的启发式和邻域函数从一种解决方案跳到另一种解决方案。我们
如何选择一套而不是另一套？在实践中，在搜索过程中切换策略经常会得到回报。我们使用的动态策略选择
将在试探法和邻域函数的组合之间切换，以尝试动态地转移到效果最好的那些策略上。对我们来说，策略是
启发式和邻域函数（包括其参数值）的特定配置。

首先，我们的代码构建了我们在求解期间要考虑的策略范围。在策略初始化，我们使用的partial函数从
functools包中部分分配参数为每个街区。另外，我们构造了一个启发式函数列表，最后我们使用乘积运算
符将邻域和启发式函数的每种组合添加为新策略。

################
## Strategies ##
#################################################
## A strategy is a particular configuration
##  of neighbourhood generator (to compute
##  the next set of candidates) and heuristic
##  computation (to select the best candidate).
##

STRATEGIES = []

# Using a namedtuple is a little cleaner than using dictionaries.
#  E.g., strategy['name'] versus strategy.name
Strategy = namedtuple('Strategy', ['name', 'neighbourhood', 'heuristic'])

def initialize_strategies():

    global STRATEGIES

    # Define the neighbourhoods (and parameters) that we would like to use
    neighbourhoods = [
        ('Random Permutation', partial(neigh.neighbours_random, num=100)),
        ('Swapped Pairs', neigh.neighbours_swap),
        ('Large Neighbourhood Search (2)', partial(neigh.neighbours_LNS, size=2)),
        ('Large Neighbourhood Search (3)', partial(neigh.neighbours_LNS, size=3)),
        ('Idle Neighbourhood (3)', partial(neigh.neighbours_idle, size=3)),
        ('Idle Neighbourhood (4)', partial(neigh.neighbours_idle, size=4)),
        ('Idle Neighbourhood (5)', partial(neigh.neighbours_idle, size=5))
    ]

    # Define the heuristics that we would like to use
    heuristics = [
        ('Hill Climbing', heur.heur_hillclimbing),
        ('Random Selection', heur.heur_random),
        ('Biased Random Selection', heur.heur_random_hillclimbing)
    ]

    # Combine every neighbourhood and heuristic strategy
    for (n, h) in product(neighbourhoods, heuristics):
        STRATEGIES.append(Strategy("%s / %s" % (n[0], h[0]), n[1], h[1]))

定义策略后，我们不一定要在搜索过程中坚持使用单个选项。取而代之的是，我们随机选择任何一种策略，
但要根据策略的执行情况对选择进行加权。我们在下面描述权重，但是对于pick_strategy功能，我们只需
要一个策略列表和一个相对权重列表（任意数量即可）。为了选择具有给定权重的随机策略，我们统一选择
一个介于0和所有权重之和之间的数字。随后，我们找到最低的索引一世一世这样索引的所有权重之和小于 
一世一世大于我们选择的随机数。这项技术有时称为轮盘赌选择，将为我们随机选择一项策略，并为那些权
重较高的策略提供更大的机会。

def pick_strategy(strategies, weights):
    # Picks a random strategy based on its weight: roulette wheel selection
    #  Rather than selecting a strategy entirely at random, we bias the
    #  random selection towards strategies that have worked well in the
    #  past (according to the weight value).
    total = sum([weights[strategy] for strategy in strategies])
    pick = random.uniform(0, total)
    count = weights[strategies[0]]

    i = 0
    while pick > count:
        count += weights[strategies[i+1]]
        i += 1

    return strategies[i]

剩下的就是描述在寻找解决方案的过程中如何增加权重。这在求解器的主while循环中以规则的时间间隔（
由TIME_INCREMENT变量定义）发生：

        # At regular intervals, switch the weighting on the strategies available.
        #  This way, the search can dynamically shift towards strategies that have
        #  proven more effective recently.
        if time.time() > time_last_switch + TIME_INCREMENT:

            time_last_switch = time.time()

回想一下，strat_improvements存储策略已进行的所有改进的总和，同时strat_time_spent存储最后间隔内
给出策略的时间。我们对每种策略所花费的总时间进行归一化，以衡量每个策略在最后一个间隔内的效果。
由于策略可能根本没有机会执行，因此我们选择少量时间作为默认值。

            # Normalize the improvements made by the time it takes to make them
            results = sorted([
                (float(strat_improvements[s]) / max(0.001, strat_time_spent[s]), s)
                for s in STRATEGIES])

现在我们已经对每种策略的执行情况进行了排名，我们添加了 ķķ 权衡最佳策略（假设我们拥有 ķķ 策略）
， k − 1ķ-1个到次佳的策略，等等。每种策略的权重都会增加，列表中最差的策略的权重只会增加1。

            # Boost the weight for the successful strategies
            for i in range(len(STRATEGIES)):
                strat_weights[results[i][1]] += len(STRATEGIES) - i

作为一项额外措施，我们人为地提高了所有未使用的策略。这样做是为了使我们不会完全忘记策略。尽管一
种策略在开始时似乎表现不佳，但在搜索的后期却可以证明是非常有用的。

                # Additionally boost the unused strategies to avoid starvation
                if results[i][0] == 0:
                    strat_weights[results[i][1]] += len(STRATEGIES)

最后，我们输出有关策略排名的一些信息（如果DEBUG_SWITCH设置了标志），然后在下一个时间间隔重置
strat_improvements和strat_time_spent变量。

            if DEBUG_SWITCH:
                print "\nComputing another switch..."
                print "Best: %s (%d)" % (results[0][1].name, results[0][0])
                print "Worst: %s (%d)" % (results[-1][1].name, results[-1][0])
                print results
                print sorted([strat_weights[STRATEGIES[i]]
                              for i in range(len(STRATEGIES))])

            strat_improvements = {strategy: 0 for strategy in STRATEGIES}
            strat_time_spent = {strategy: 0 for strategy in STRATEGIES}

讨论区

在本章中，我们看到了用相对少量的代码可以解决流水车间调度的复杂优化问题的方法。很难找到诸如流水
车间之类的大型优化问题的最佳解决方案。在这种情况下，我们可以转向近似技术（例如本地搜索）来计算
足够好的解。通过本地搜索，我们可以从一种解决方案过渡到另一种解决方案，旨在找到质量好的解决方案
。

本地搜索的一般直觉可以应用于各种各样的问题。我们专注于（1）从一个候选解决方案生成问题的相关解
决方案的邻域，以及（2）建立评估和比较解决方案的方法。有了这两个组成部分，当最好的选择太难计算
时，我们可以使用局部搜索范式找到有价值的解决方案。

我们没有使用任何一种策略来解决问题，而是看到了如何在解决过程中动态选择一种策略来进行转移。这种
简单而强大的技术使程序能够混合和匹配针对当前问题的部分策略，这也意味着开发人员不必手工定制该策
略。

Google 翻译

原文

提供更好的翻译建议
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
